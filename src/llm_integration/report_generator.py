"""
Gerador de Relat√≥rios de Efici√™ncia usando LLM.

Suporta Ollama (local, gr√°tis) e OpenAI (nuvem, pago).
"""
import os
from typing import Dict, List, Optional
from pathlib import Path
from datetime import datetime


class ReportGenerator:
    """Gera relat√≥rios anal√≠ticos de efici√™ncia usando LLM."""
    
    def __init__(self, provider: str = "ollama", model: str = None, api_key: str = None):
        """
        Inicializa o gerador de relat√≥rios.
        
        Args:
            provider: "ollama" (local, gr√°tis) ou "openai" (nuvem, pago)
            model: Nome do modelo. Se None, usa padr√£o:
                  - Ollama: "llama2"
                  - OpenAI: "gpt-3.5-turbo"
            api_key: API key (apenas para OpenAI)
        """
        self.provider = provider.lower()
        
        if self.provider == "ollama":
            try:
                import ollama
                self.client = ollama
                self.model = model or "llama2"
                print(f"‚úÖ Ollama configurado com modelo: {self.model}")
            except ImportError:
                raise ImportError(
                    "Ollama n√£o instalado! Execute: pip install ollama\n"
                    "E instale o Ollama: https://ollama.ai/download/windows"
                )
        
        elif self.provider == "openai":
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
                self.model = model or "gpt-3.5-turbo"
                print(f"‚úÖ OpenAI configurado com modelo: {self.model}")
            except ImportError:
                raise ImportError("OpenAI n√£o instalado! Execute: pip install openai")
        
        else:
            raise ValueError(f"Provider '{provider}' n√£o suportado. Use 'ollama' ou 'openai'")
    
    def generate_report(
        self,
        metrics: Dict,
        ga_stats: Dict,
        route_details: List[Dict]
    ) -> str:
        """
        Gera relat√≥rio de efici√™ncia.
        
        Args:
            metrics: M√©tricas gerais (dist√¢ncia, fitness, etc.)
            ga_stats: Estat√≠sticas do AG (gera√ß√µes, muta√ß√µes, etc.)
            route_details: Detalhes de cada rota
            
        Returns:
            Relat√≥rio em Markdown/texto
        """
        
        print(f"\nüìä Gerando relat√≥rio com {self.provider.upper()}...")
        print(f"   Rotas analisadas: {len(route_details)}")
        
        # Construir prompt
        prompt = self._build_report_prompt(metrics, ga_stats, route_details)
        
        # Chamar LLM
        try:
            if self.provider == "ollama":
                response = self._call_ollama(prompt)
            else:  # openai
                response = self._call_openai(prompt)
            
            print(f"   ‚úÖ Relat√≥rio gerado com sucesso!")
            return response
        
        except Exception as e:
            print(f"   ‚ùå Erro ao gerar relat√≥rio: {e}")
            return self._generate_fallback_report(metrics, ga_stats, route_details)
    
    def _call_ollama(self, prompt: str) -> str:
        """Chama Ollama local."""
        response = self.client.chat(model=self.model, messages=[
            {
                'role': 'system',
                'content': (
                    'Voc√™ √© um analista s√™nior de log√≠stica e otimiza√ß√£o. '
                    'Analise dados de rotas otimizadas e gere relat√≥rios '
                    'DETALHADOS, ANAL√çTICOS e ACION√ÅVEIS. Inclua:\n'
                    '- An√°lise quantitativa (n√∫meros, percentuais)\n'
                    '- Insights qualitativos (padr√µes, problemas)\n'
                    '- Recomenda√ß√µes pr√°ticas (melhorias, ajustes)\n'
                    'Use formata√ß√£o Markdown clara. Seja profissional mas direto.'
                )
            },
            {
                'role': 'user',
                'content': prompt
            }
        ])
        
        return response['message']['content']
    
    def _call_openai(self, prompt: str) -> str:
        """Chama OpenAI API."""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Voc√™ √© um analista s√™nior de log√≠stica e otimiza√ß√£o. "
                        "Analise dados de rotas otimizadas e gere relat√≥rios "
                        "DETALHADOS, ANAL√çTICOS e ACION√ÅVEIS. Inclua:\n"
                        "- An√°lise quantitativa (n√∫meros, percentuais)\n"
                        "- Insights qualitativos (padr√µes, problemas)\n"
                        "- Recomenda√ß√µes pr√°ticas (melhorias, ajustes)\n"
                        "Use formata√ß√£o Markdown clara. Seja profissional mas direto."
                    )
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
    
    def _build_report_prompt(self, metrics, ga_stats, route_details):
        """Constr√≥i prompt para gera√ß√£o de relat√≥rio."""
        
        prompt = f"""
Analise os dados de otimiza√ß√£o de rotas e gere um relat√≥rio completo:

M√âTRICAS GERAIS:
- Fitness (dist√¢ncia total): {metrics.get('total_distance', 'N/A')} km
- Ve√≠culos utilizados: {len(route_details)} de {metrics.get('total_vehicles', 'N/A')}
- Entregas atendidas: {metrics.get('total_deliveries', 'N/A')}
- Viola√ß√µes: {metrics.get('violations', 0)}

ESTAT√çSTICAS DO ALGORITMO GEN√âTICO:
- Gera√ß√µes: {ga_stats.get('current_generation', 'N/A')}
- Crossovers: {ga_stats.get('total_crossovers', 'N/A')}
- Muta√ß√µes: {ga_stats.get('total_mutations', 'N/A')}
- Tipo de sele√ß√£o: {ga_stats.get('selection_type', 'N/A')}
- Tipo de crossover: {ga_stats.get('crossover_type', 'N/A')}

DETALHES POR VE√çCULO:
"""
        
        for i, route in enumerate(route_details, 1):
            prompt += f"""
Ve√≠culo {i} - {route.get('vehicle_name', f'Ve√≠culo {i}')}:
- Entregas: {route.get('num_deliveries', 0)}
- Dist√¢ncia: {route.get('distance_km', 0):.1f} km
- Autonomia: {route.get('autonomy_km', 'N/A')} km
- Carga: {route.get('load_kg', 0):.1f} kg
- Capacidade: {route.get('capacity_kg', 'N/A')} kg
- Utiliza√ß√£o: {route.get('capacity_usage_%', 0):.1f}%
- Pontos: {' ‚Üí '.join(route.get('points', []))}
"""
        
        prompt += """

GERE UM RELAT√ìRIO COMPLETO COM:
1. Resumo executivo (3-4 par√°grafos)
2. Tabela de m√©tricas principais (Markdown)
3. An√°lise detalhada por ve√≠culo (performance, problemas, pontos de aten√ß√£o)
4. Insights e recomenda√ß√µes (m√≠nimo 3)
5. An√°lise do algoritmo gen√©tico (converg√™ncia, qualidade)
6. Conclus√£o e pr√≥ximos passos

Use Markdown. Seja espec√≠fico e acion√°vel. Identifique problemas e sugira solu√ß√µes.
"""
        
        return prompt
    
    def _generate_fallback_report(self, metrics, ga_stats, route_details):
        """Gera relat√≥rio b√°sico caso o LLM falhe."""
        
        now = datetime.now()
        
        report = f"""
# üìä RELAT√ìRIO DE EFICI√äNCIA DE ROTAS

**Data:** {now.strftime('%d/%m/%Y %H:%M')}  
**Per√≠odo:** Opera√ß√£o Di√°ria  
**Sistema:** Algoritmo Gen√©tico VRP v1.0

---

## üìà RESUMO EXECUTIVO

A otimiza√ß√£o de hoje utilizou **{len(route_details)} ve√≠culos** para atender **{metrics.get('total_deliveries', 'N/A')} entregas**, 
percorrendo uma dist√¢ncia total de **{metrics.get('total_distance', 'N/A')} km**.

---

## üìä M√âTRICAS PRINCIPAIS

| M√©trica | Valor |
|---------|-------|
| Dist√¢ncia Total | {metrics.get('total_distance', 'N/A')} km |
| Ve√≠culos Utilizados | {len(route_details)} de {metrics.get('total_vehicles', 'N/A')} |
| Entregas Atendidas | {metrics.get('total_deliveries', 'N/A')} |
| Viola√ß√µes | {metrics.get('violations', 0)} |

---

## üöê AN√ÅLISE POR VE√çCULO

"""
        
        for i, route in enumerate(route_details, 1):
            autonomy_usage = (route.get('distance_km', 0) / route.get('autonomy_km', 1) * 100) if route.get('autonomy_km', 0) > 0 else 0
            
            report += f"""
### Ve√≠culo {i} - {route.get('vehicle_name', f'Ve√≠culo {i}')}

**M√©tricas:**
- Entregas: {route.get('num_deliveries', 0)}
- Dist√¢ncia: {route.get('distance_km', 0):.1f} km ({autonomy_usage:.1f}% da autonomia)
- Carga: {route.get('load_kg', 0):.1f} kg ({route.get('capacity_usage_%', 0):.1f}% da capacidade)
- Rota: {' ‚Üí '.join(route.get('points', []))}

"""
        
        report += f"""
---

## ü§ñ ALGORITMO GEN√âTICO

**Estat√≠sticas:**
- Gera√ß√µes: {ga_stats.get('current_generation', 'N/A')}
- Crossovers: {ga_stats.get('total_crossovers', 'N/A')}
- Muta√ß√µes: {ga_stats.get('total_mutations', 'N/A')}
- Sele√ß√£o: {ga_stats.get('selection_type', 'N/A')}
- Crossover: {ga_stats.get('crossover_type', 'N/A')}

---

## üí° RECOMENDA√á√ïES

1. Monitorar utiliza√ß√£o de capacidade dos ve√≠culos
2. Verificar rotas para otimiza√ß√£o de dist√¢ncia
3. Considerar balanceamento de carga entre ve√≠culos

---

## üéØ CONCLUS√ÉO

A otimiza√ß√£o foi conclu√≠da com sucesso. Todas as entregas foram alocadas respeitando as restri√ß√µes.

---

**Relat√≥rio gerado automaticamente**  
Sistema VRP-AG v1.0 | Tech Challenge FIAP
"""
        
        return report
    
    def save_report(self, report: str, prefix: str = "relatorio") -> Path:
        """
        Salva relat√≥rio em arquivo Markdown.
        
        Args:
            report: String com relat√≥rio
            prefix: Prefixo do nome do arquivo
            
        Returns:
            Path do arquivo salvo
        """
        output_dir = Path("outputs/reports")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{prefix}_{timestamp}.md"
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\n{'='*70}")
        print(f"‚úÖ RELAT√ìRIO SALVO!")
        print(f"{'='*70}")
        print(f"üìÅ Local: {filepath.absolute()}")
        print(f"üí° Abra o arquivo para visualizar o relat√≥rio completo!")
        print(f"{'='*70}\n")
        
        return filepath

